# Introduction
- LDR是一个基于Minimind-v的多模态小模型，是作者在学习大模型相关知识时的中间产物
- 相较于Minimind-v，LDR模型增加了对视频及音频的模态理解能力
- 不一定支持视频，主要是模型能力不一定够

# 数据集构造

## 音频数据
- 音频转文本
  - 使用tts生成语音数据
- 音频对话输入
  - 将对话数据的input使用tts转化为对话数据
- 音频描述
  - 使用clapcap对音频进行描述
- 音频+图像对话

## 图像数据
- 使用minimind-v使用的图像数据进行训练

## 文本数据
- 使用minimind使用的文本数据进行训练

## 视频数据
- 如果要弄的话可以找一些开源数据集

# 模型结构

## 位置编码
- 基于mRoPE的思想加入了音频位置编码
- 具体编码方式需要后续考虑一下，是否要使用mrope的文本对角线编码方式

## 模态输入
- 输入内容应当为一个dict list
- 每个dict内为一种模态，dict的顺序代表输入的时序

# 模型测试
- 需要对模型结果进行测试，在开源benchmark上

# ToDo

- 原生的音频输出能力